import { FastifyPluginAsync } from 'fastify'
import { TypeBoxTypeProvider } from '@fastify/type-provider-typebox'
import fastifyMultipart from '@fastify/multipart'
import fastifyStatic from '@fastify/static'
import fs from 'node:fs'
import path from 'node:path'
import crypto from 'node:crypto'
import { chunkUpload, singleUpload, uploadBase, uploadBatch } from '../../schema/upload.js'
import { UPLOAD_DIR } from '../../utils/index.js'
import cors from '@fastify/cors'
import { handleBatch } from './handleBatch.js'
import { ALLOWED_TYPES, MAX_FILE_SIZE } from '../../utils/upload.js'
import { handleTrunk } from './handleTrunk.js'

const upload: FastifyPluginAsync = async (fastify, opts): Promise<void> => {
  // Ensure upload directory exists
  if (!fs.existsSync(UPLOAD_DIR)) {
    fs.mkdirSync(UPLOAD_DIR, { recursive: true })
  }

  fastify.register(cors, {
      origin: ['http://localhost:3001', 'http://localhost:3000'], // Allow requests from this origin
      // methods: ['GET', 'POST'], // Allow these methods
      credentials: true, // Enable cookies
    },
  )

  // Serve static files  this /upload/static/
  fastify.register(fastifyStatic, {
    root: UPLOAD_DIR,
    prefix: '/static/',
  })

  fastify.withTypeProvider<TypeBoxTypeProvider>().get('', {
    schema: uploadBase,
    async handler(req, reply) {
      const { hashId } = req.query
      if (hashId) {
        // ÈÅçÂéÜËØªÂèñUPLOAD_DIRÊñá‰ª∂Â§π‰∏≠ÁöÑÊâÄÊúâÊñá‰ª∂Âêç
        const files = fs.readdirSync(UPLOAD_DIR)
        const fileName = files.find((s) => s.includes(hashId))
        // return reply.sendFile(`${fileName}`)
        return reply.download(`${fileName}`, `${(fileName || '').split('-')[1]}`)

      } else {
        return reply.code(400).send({
          msg: `Êú™ÊâæÂà∞ÊîØÊåÅÁöÑ${hashId}`,
        })
      }
    },
  })

  // Register multipart plugin
  fastify.register(fastifyMultipart, {
    // attachFieldsToBody: true,
    // sharedSchemaId: '#mySharedSchema',
    limits: {
      files: 3,
      fileSize: MAX_FILE_SIZE,
    },
  })

  fastify.withTypeProvider<TypeBoxTypeProvider>().post(
    '/single',
    {
      schema: singleUpload,
    },
    async function (req, reply) {
      const data = await req.file()
      if (!data) {
        return reply.code(400).send({ error: 'No file uploaded' })
      }
      if (!ALLOWED_TYPES.includes(data.mimetype)) {
        return reply.code(400).send({ error: 'File type not allowed' })
      }
      // Êñ∞Â¢ûÁßí‰º†ÁöÑÈÄªËæë
      // const orgHash = hashes[0] as string;
      // const fileNameList = fs.readdirSync(UPLOAD_DIR)
      // console.log("üöÄ ~ file:index.ts, line:93-----", fileNameList)
      // const fileFullName = fileNameList.find(a => a.includes(orgHash))
      // if (fileFullName) {
      //     return reply.code(200).send({
      //         message: 'one second File uploaded successfully',
      //         fileUrl: `/zuul/${fileFullName}`,
      //         fileHash: orgHash
      //     })
      // }

      const hash = crypto.createHash('sha256')
      const chunks: Buffer[] = []
      let size = 0

      for await (const chunk of data.file) {
        chunks.push(chunk)
        hash.update(chunk)
        size += chunk.length

        if (size > MAX_FILE_SIZE) {
          return reply.code(413).send({ error: 'File too large' })
        }
      }

      const fileHash = hash.digest('hex')
      const fileName = `${fileHash}-${data.filename}`
      const filePath = path.join(UPLOAD_DIR, fileName)
      await fs.promises.writeFile(filePath, Buffer.concat(chunks))

      const fileUrl = `/zuul/${fileName}`

      return {
        message: 'File uploaded successfully',
        fileUrl,
        fileHash,
      }
    },
  )

  // Register batch upload handler
  fastify.withTypeProvider<TypeBoxTypeProvider>().post('/batch', {
    schema: uploadBatch,
    handler: handleBatch,
  })

  fastify.post(
    '/chunk',
    {
      schema: chunkUpload,
    },
    handleTrunk,
  )


}

export default upload
